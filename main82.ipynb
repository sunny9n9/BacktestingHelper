{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [NOTEBOOK TO ADD TO DATABASE] -------------------\n",
    "# [INCLUDES] ------------------------------------\n",
    "from Includes import *\n",
    "import yfinance\n",
    "import sqlite3\n",
    "import pandas\n",
    "import random, time\n",
    "\n",
    "SYMBOLS = [\n",
    "    'GOLDBEES.NS',   # Gold ETF (India)\n",
    "    'SILVERETF.NS',  # Silver ETF (India)\n",
    "    'GC=F',          # Gold futures (global)\n",
    "    'SI=F'           # Silver futures (global)\n",
    "]\n",
    "\n",
    "\n",
    "TABLE_NAMES = [\n",
    "    'goldbees_india',\n",
    "    'silveretf_india',\n",
    "    'gold_global',\n",
    "    'silver_global'\n",
    "]\n",
    "\n",
    "\n",
    "for entries, table in zip(SYMBOLS, TABLE_NAMES):\n",
    "        \n",
    "    # [CREATE TABLE] ----------------------------- \n",
    "    TABLE_NAME = table\n",
    "    conn = sqlite3.connect(\"databases/indices.db\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # [GET DATA] -----------------------------\n",
    "    time.sleep(random.uniform(0.5, 1.1))\n",
    "    TICKER = entries\n",
    "    PERIOD = \"max\"\n",
    "    def _Fetch():\n",
    "        ticker_data = yfinance.download(tickers=TICKER, period=PERIOD, multi_level_index=False)\n",
    "        if ticker_data is None or ticker_data.empty:\n",
    "            print(\"[FETCH] Empty ticker data returned\")\n",
    "            continue\n",
    "        else:\n",
    "            # print(ticker_data.head())\n",
    "            return ticker_data\n",
    "    ticker_data = _Fetch()\n",
    "\n",
    "    # [FORMAT DATA] -----------------------------\n",
    "    # ticker_data.drop(columns=['Volume'], inplace=True)\n",
    "    ticker_data.reset_index(inplace=True) # remove the date from index\n",
    "    ticker_data.rename(columns={'Date' : 'date', 'Close' : 'close', 'High' : 'high', 'Low' : 'low', 'Open' : 'open', 'Volume' : 'volume'}, inplace=True)\n",
    "    print(ticker_data)\n",
    "\n",
    "    # [SAVE TO DATABASES' TABLE] -----------------------------\n",
    "    ticker_data.to_sql(table, conn, if_exists='replace', index=False)\n",
    "    df = pandas.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "\n",
    "    # [PLOT FOR VERIFICATION] -----------------------------\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def plotter(conn, table):\n",
    "        df = pandas.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "        df['date'] = pandas.to_datetime(df['date']) # IMPORTANT\n",
    "        df.set_index('date', inplace=True)\n",
    "\n",
    "        plt.plot(df['close'])\n",
    "        plt.show()\n",
    "\n",
    "    plotter(conn, table)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639d69ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: ['nifty50', 'nifty100', 'nifty200', 'nifty500', 'midcap100', 'midcap50', 'smallcap100', 'smallcap50', 'banknifty', 'psu_bank', 'private_bank', 'it', 'auto', 'metal', 'pharma', 'fmcg', 'energy', 'realty', 'infra', 'finance', 'media', 'indiavix', 'etf_bankbees', 'etf_psubankbees', 'etf_itbees', 'etf_pharmabees', 'etf_cpse', 'etf_midcap', 'etf_smallcap', 'etf_niftybees', 'etf_juniorbees', 'etf_infrabees', 'etf_energy', 'goldbees_india', 'silveretf_india', 'gold_global', 'silver_global']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"databases/indices.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = [t[0] for t in cur.fetchall()]\n",
    "\n",
    "print(\"Tables:\", tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56c3aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking nifty50...\n",
      "[OK] nifty50 seems valid.\n",
      "\n",
      "Checking nifty100...\n",
      "[OK] nifty100 seems valid.\n",
      "\n",
      "Checking nifty200...\n",
      "[OK] nifty200 seems valid.\n",
      "\n",
      "Checking nifty500...\n",
      "[OK] nifty500 seems valid.\n",
      "\n",
      "Checking midcap100...\n",
      "[EMPTY] midcap100 has no data.\n",
      "\n",
      "Checking midcap50...\n",
      "[OK] midcap50 seems valid.\n",
      "\n",
      "Checking smallcap100...\n",
      "[EMPTY] smallcap100 has no data.\n",
      "\n",
      "Checking smallcap50...\n",
      "[EMPTY] smallcap50 has no data.\n",
      "\n",
      "Checking banknifty...\n",
      "[OK] banknifty seems valid.\n",
      "\n",
      "Checking psu_bank...\n",
      "[OK] psu_bank seems valid.\n",
      "\n",
      "Checking private_bank...\n",
      "[EMPTY] private_bank has no data.\n",
      "\n",
      "Checking it...\n",
      "[OK] it seems valid.\n",
      "\n",
      "Checking auto...\n",
      "[OK] auto seems valid.\n",
      "\n",
      "Checking metal...\n",
      "[OK] metal seems valid.\n",
      "\n",
      "Checking pharma...\n",
      "[OK] pharma seems valid.\n",
      "\n",
      "Checking fmcg...\n",
      "[OK] fmcg seems valid.\n",
      "\n",
      "Checking energy...\n",
      "[OK] energy seems valid.\n",
      "\n",
      "Checking realty...\n",
      "[OK] realty seems valid.\n",
      "\n",
      "Checking infra...\n",
      "[OK] infra seems valid.\n",
      "\n",
      "Checking finance...\n",
      "[EMPTY] finance has no data.\n",
      "\n",
      "Checking media...\n",
      "[OK] media seems valid.\n",
      "\n",
      "Checking indiavix...\n",
      "[OK] indiavix seems valid.\n",
      "\n",
      "Checking etf_bankbees...\n",
      "[OK] etf_bankbees seems valid.\n",
      "\n",
      "Checking etf_psubankbees...\n",
      "[OK] etf_psubankbees seems valid.\n",
      "\n",
      "Checking etf_itbees...\n",
      "[OK] etf_itbees seems valid.\n",
      "\n",
      "Checking etf_pharmabees...\n",
      "[OK] etf_pharmabees seems valid.\n",
      "\n",
      "Checking etf_cpse...\n",
      "[OK] etf_cpse seems valid.\n",
      "\n",
      "Checking etf_midcap...\n",
      "[OK] etf_midcap seems valid.\n",
      "\n",
      "Checking etf_smallcap...\n",
      "[EMPTY] etf_smallcap has no data.\n",
      "\n",
      "Checking etf_niftybees...\n",
      "[OK] etf_niftybees seems valid.\n",
      "\n",
      "Checking etf_juniorbees...\n",
      "[OK] etf_juniorbees seems valid.\n",
      "\n",
      "Checking etf_infrabees...\n",
      "[OK] etf_infrabees seems valid.\n",
      "\n",
      "Checking etf_energy...\n",
      "[OK] etf_energy seems valid.\n",
      "\n",
      "Checking goldbees_india...\n",
      "[OK] goldbees_india seems valid.\n",
      "\n",
      "Checking silveretf_india...\n",
      "[OK] silveretf_india seems valid.\n",
      "\n",
      "Checking gold_global...\n",
      "[OK] gold_global seems valid.\n",
      "\n",
      "Checking silver_global...\n",
      "[OK] silver_global seems valid.\n"
     ]
    }
   ],
   "source": [
    "bad_tables = []\n",
    "\n",
    "for table in tables:\n",
    "    print(f\"\\nChecking {table}...\")\n",
    "    try:\n",
    "        df = pandas.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "        \n",
    "        # CASE 1 — table has zero rows\n",
    "        if df.empty:\n",
    "            print(f\"[EMPTY] {table} has no data.\")\n",
    "            bad_tables.append(table)\n",
    "            continue\n",
    "        \n",
    "        # CASE 2 — table has only 1 row (invalid ticker)\n",
    "        if len(df) <= 1:\n",
    "            print(f\"[BAD] {table} has only {len(df)} row(s).\")\n",
    "            bad_tables.append(table)\n",
    "            continue\n",
    "        \n",
    "        # CASE 3 — date column is missing or broken\n",
    "        if 'date' not in df.columns:\n",
    "            print(f\"[BAD] {table} has no 'date' column.\")\n",
    "            bad_tables.append(table)\n",
    "            continue\n",
    "        \n",
    "        # CASE 4 — all dates identical → bad ticker\n",
    "        if df['date'].nunique() == 1:\n",
    "            print(f\"[BAD] {table} has only one unique date.\")\n",
    "            bad_tables.append(table)\n",
    "            continue\n",
    "        \n",
    "        print(f\"[OK] {table} seems valid.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {table}: {e}\")\n",
    "        bad_tables.append(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f898923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping table midcap100...\n",
      "Dropping table smallcap100...\n",
      "Dropping table smallcap50...\n",
      "Dropping table private_bank...\n",
      "Dropping table finance...\n",
      "Dropping table etf_smallcap...\n"
     ]
    }
   ],
   "source": [
    "for table in bad_tables:\n",
    "    print(f\"Dropping table {table}...\")\n",
    "    cur.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    conn.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
